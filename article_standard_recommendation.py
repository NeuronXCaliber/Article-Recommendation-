# -*- coding: utf-8 -*-
"""Article_standard_Recommendation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gxfsIkEVCYBJ2lRGwGW0ngNd8RXgt5Im
"""

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
data=pd.read_csv('/content/COMPLETE_DATA_RATINGS_CLUSTER.csv')
data.head()

data = data.sample(frac=1)
data = data.sample(frac=1).reset_index()
data.head()

data=data.drop(['index'],axis=1)
data.head()

data.isnull().sum()

x=data['cluster_student'].tolist()
for i in range(len(x)):
  if(x[i]==1):
    x[i]='one'
  elif(x[i]==2):
    x[i]='two'
  elif(x[i]==3):
    x[i]='three'
  else:
    x[i]='four'
data['cluster_student']=x
data.head()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import pandas as pd
import seaborn as sns
import re,nltk,json
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import regularizers
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras import models
from keras import layers
from tensorflow.keras.layers import LSTM,GRU
from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score
from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
np.random.seed(42)
class color: # Text style
   PURPLE = '\033[95m'
   CYAN = '\033[96m'
   DARKCYAN = '\033[36m'
   BLUE = '\033[94m'
   GREEN = '\033[92m'
   YELLOW = '\033[93m'
   RED = '\033[91m'
   BOLD = '\033[1m'
   UNDERLINE = '\033[4m'
   END = '\033[0m'

# Cleaning Data [Remove unncessary symbols]
def cleaning_data(row):
      headlines = re.sub('[^\u0980-\u09FF]',' ',str(row)) #removing unnecessary punctuation
      return headlines
# Apply the function into the dataframe
data['cleaned'] = data['title'].apply(cleaning_data)  

# print some cleaned reviews from the dataset
sample_data = [20,40,50,55,70,90,95,100,110]
for i in sample_data:
  print('Original: ',data.title[i],'\nCleaned:',
           data.cleaned[i],'\n','Category:-- ',data.ratings[i],'\n')

# Cleaning Data [Remove unncessary symbols]
def cleaning_data(row):
      headlines = re.sub('[^\u0980-\u09FF]',' ',str(row)) #removing unnecessary punctuation
      return headlines
# Apply the function into the dataframe
data['cleaned'] = data['article'].apply(cleaning_data)  

# print some cleaned reviews from the dataset
sample_data = [20,40,50,55,70,90,95,100,110]
for i in sample_data:
  print('Original: ',data.article[i],'\nCleaned:',
           data.cleaned[i],'\n','Category:-- ',data.ratings[i],'\n')

def data_summary(data):
    
    """
    This function will print the summary of the headlines and words distribution in the dataset. 
    
    Args:
        dataset: list of cleaned sentences   
        
    Returns:
        Number of documnets per class: int 
        Number of words per class: int
        Number of unique words per class: int
    """
    documents = []
    words = []
    u_words = []
    total_u_words = [word.strip().lower() for t in list(data.cleaned) for word in t.strip().split()]
    class_label= [k for k,v in data.ratings.value_counts().to_dict().items()]
  # find word list
    for label in class_label: 
        word_list = [word.strip().lower() for t in list(data[data.ratings==label].cleaned) for word in t.strip().split()]
        counts = dict()
        for word in word_list:
                counts[word] = counts.get(word, 0)+1
        # sort the dictionary of word list  
        ordered = sorted(counts.items(), key= lambda item: item[1],reverse = True)
        # Documents per class
        documents.append(len(list(data[data.ratings==label].cleaned)))
        # Total Word per class
        words.append(len(word_list))
        # Unique words per class 
        u_words.append(len(np.unique(word_list)))
       
        print("\nClass Name : ",label)
        print("Number of Documents:{}".format(len(list(data[data.ratings==label].cleaned))))  
        print("Number of Words:{}".format(len(word_list))) 
        print("Number of Unique Words:{}".format(len(np.unique(word_list)))) 
        print("Most Frequent Words:\n")
        for k,v in ordered[:10]:
              print("{}\t{}".format(k,v))
    print("Total Number of Unique Words:{}".format(len(np.unique(total_u_words))))           
   
    return documents,words,u_words,class_label

#call the fucntion
documents,words,u_words,class_names = data_summary(data)

data_matrix = pd.DataFrame({'Total Documents':documents,
                            'Total Words':words,
                            'Unique Words':u_words,
                            'Class Names':class_names})
df = pd.melt(data_matrix, id_vars="Class Names", var_name="Category", value_name="Values")
plt.figure(figsize=(8, 6))
ax = plt.subplot()

sns.barplot(data=df,x='Class Names', y='Values' ,hue='Category')
ax.set_xlabel('Class Names') 
ax.set_title('Data Statistics')

ax.xaxis.set_ticklabels(class_names, rotation=45);

#==================================================
                                       ################# Label Encoding Function #########
                                       #==================================================

def label_encoding(category,bool):
    """
    This function will return the encoded labels in array format. 
    
    Args:
        category: series of class names(str)
        bool: boolean (True or False)
        
    Returns:
        labels: numpy array 
    """
    le = LabelEncoder()
    le.fit(category)
    encoded_labels = le.transform(category)
    labels = np.array(encoded_labels) # Converting into numpy array
    class_names =le.classes_ ## Define the class names again
    if bool == True:
        print("\n\t\t\t===== Label Encoding =====","\nClass Names:-->",le.classes_)
        for i in sample_data:
            print(category[i],' ', encoded_labels[i],'\n')

    return labels



                           #===========================================================
                           ################# Dataset Splitting Function ###############
                           #=========================================================== 

def dataset_split(headlines,category):
    """
    This function will return the splitted (90%-10%-10%) feature vector . 
    
    Args:
        headlines: sequenced headlines 
        category: encoded lables (array) 
        
    Returns:
        X_train: training data 
        X_valid: validation data
        X_test : testing feature vector 
        y_train: training encoded labels (array) 
        y_valid: training encoded labels (array) 
        y_test : testing encoded labels (array) 
    """

    X,X_test,y,y_test = train_test_split(headlines,category,test_size = 0.1,random_state =1,shuffle=False)
    X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size = 0.2,random_state =1,shuffle=False)
    print(color.BOLD+"\nDataset Distribution:\n"+color.END)
    print("\tSet Name","\t\tSize")
    print("\t========\t\t======")

    print("\tFull\t\t\t",len(headlines),
        "\n\tTraining\t\t",len(X_train),
        "\n\tTest\t\t\t",len(X_test),
        "\n\tValidation\t\t",len(X_valid))
  
    return X_train,X_valid,X_test,y_train,y_valid,y_test

labels = label_encoding(data.ratings,True)

data['mer'] = data[['cluster_student','title','article']].agg(' '.join, axis=1)
data

X_train,X_valid,X_test,y_train,y_valid,y_test = dataset_split(data.mer,labels)

vocab_size = 5700
embedding_dim = 128
max_length = 150
trunc_type='post'
padding_type='post'
oov_tok = "<OOV>"

def padded_headlines(original,encoded,padded):
  '''
  print the samples padded headlines
  '''
  print(color.BOLD+"\n\t\t\t====== Encoded Sequences ======"+color.END,"\n")  
  print(original,"\n",encoded) 
  print(color.BOLD+"\n\t\t\t====== Paded Sequences ======\n"+color.END,original,"\n",padded)

# Train Data Tokenization
tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(X_train)
word_index = tokenizer.word_index
train_sequences = tokenizer.texts_to_sequences(X_train)
train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)

#============================== Tokenizer Info =================================
(word_counts,word_docs,word_index,document_count) = (tokenizer.word_counts,
                                                       tokenizer.word_docs,
                                                       tokenizer.word_index,
                                                       tokenizer.document_count)
def tokenizer_info(mylist,bool):
  ordered = sorted(mylist.items(), key= lambda item: item[1],reverse = bool)
  for w,c in ordered[:10]:
    print(w,"\t",c)
  #=============================== Print all the information =========================
print(color.BOLD+"\t\t\t====== Tokenizer Info ======"+color.END)   
print("Words --> Counts:")
tokenizer_info(word_counts,bool =True )
print("\nWords --> Documents:")
tokenizer_info(word_docs,bool =True )
print("\nWords --> Index:")
tokenizer_info(word_index,bool =True )    
print("\nTotal Documents -->",document_count)
print(f"Found {len(word_index)} unique tokens")

padded_headlines(X_train[20],train_sequences[20],train_padded[20])

# Validation Data Tokenization
validation_sequences = tokenizer.texts_to_sequences(X_valid)
validation_padded = pad_sequences(validation_sequences, padding=padding_type , maxlen=max_length)
#padded_headlines(X_valid[1150],validation_sequences[1],validation_padded[1])

# Test Data Tokenization
test_sequences = tokenizer.texts_to_sequences(X_test)
test_padded = pad_sequences(test_sequences, padding=padding_type , maxlen=max_length)
#padded_headlines(X_test[800],test_sequences[800],test_padded[800])

# Labels Tokenization
#label_tokenizer = Tokenizer()
#label_tokenizer.fit_on_texts(dataset.category)

train_label_seq = y_train
valid_label_seq = y_valid
testing_label_seq = y_test

#print(train_label_seq.shape)
#print(valid_label_seq.shape)
#print(testing_label_seq.shape)

keras.backend.clear_session()
accuracy_threshold = 0.97
vocab_size = 5700
embedding_dim = 128
max_length = 150
num_category = 5

class myCallback(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
      if(logs.get('accuracy')>accuracy_threshold):
        print("\nReached %2.2f%% accuracy so we will stop trianing" % (accuracy_threshold*100))
        self.model.stop_training = True

acc_callback = myCallback()
# Saved the Best Model
filepath = "Model.h5"
checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True, 
                                             save_weights_only=False, mode='max',min_delta=0.001)
callback_list = [acc_callback, checkpoint] 
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Bidirectional(GRU(64,dropout=0.2)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64,activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(20,activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(num_category, activation='softmax')
])
model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary()

num_epochs = 5
batch = 64
history = model.fit(train_padded, train_label_seq, 
                    epochs=num_epochs,
                    batch_size = batch,
                    validation_data=(validation_padded, valid_label_seq), 
                    verbose=1,
                    callbacks = callback_list)

plt.plot(model.evaluate(train_padded,train_label_seq))
plt.plot(model.evaluate(validation_padded,valid_label_seq))
plt.plot(model.evaluate(test_padded,testing_label_seq))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['training accuracy','validation accuracy'],loc='upper left')
plt.title("accuracy range")

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training loss','validation loss'],loc='upper left')
plt.title("training vs validation loss range")

from sklearn.metrics import classification_report, confusion_matrix
from sklearn import metrics
import numpy as np
# load the Saved model from directory
model = load_model("Model.h5")
predictions = model.predict(test_padded)
y_pred = np.argmax(predictions, axis=1)

cm = confusion_matrix(testing_label_seq, y_pred) 
error1=np.sqrt(metrics.mean_squared_error(y_pred,testing_label_seq))
error2=metrics.mean_squared_error(y_pred,testing_label_seq)
# Transform to df for easier plotting

print('GRU \nAccuracy: {0:.2f}'.format(accuracy_score(testing_label_seq, y_pred)*100))

print("Root Mean Squared Error rate : ",error1)
print("Mean Squared Error rate : ",error2)

keras.backend.clear_session()
accuracy_threshold = 0.97
vocab_size = 5700
embedding_dim = 128
max_length = 150
num_category = 5

class myCallback(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
      if(logs.get('accuracy')>accuracy_threshold):
        print("\nReached %2.2f%% accuracy so we will stop trianing" % (accuracy_threshold*100))
        self.model.stop_training = True

acc_callback = myCallback()
# Saved the Best Model
filepath = "Model1.h5"
checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True, 
                                             save_weights_only=False, mode='max',min_delta=0.001)
callback_list = [acc_callback, checkpoint] 
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Bidirectional(LSTM(64,dropout=0.2)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64,activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(20,activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(num_category, activation='softmax')
])
model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary()

num_epochs = 5
batch = 64
history1 = model.fit(train_padded, train_label_seq, 
                    epochs=num_epochs,
                    batch_size = batch,
                    validation_data=(validation_padded, valid_label_seq), 
                    verbose=1,
                    callbacks = callback_list)

plt.plot(model.evaluate(train_padded,train_label_seq))
plt.plot(model.evaluate(validation_padded,valid_label_seq))
plt.plot(model.evaluate(test_padded,testing_label_seq))

plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.legend(['training accuracy','validation accuracy'],loc='upper left')
plt.title("accuracy range")

plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.legend(['training loss','validation loss'],loc='upper left')
plt.title("training vs validation loss range")

from sklearn.metrics import classification_report, confusion_matrix
from sklearn import metrics
import numpy as np
# load the Saved model from directory
model = load_model("Model1.h5")
predictions = model.predict(test_padded)
y_pred = np.argmax(predictions, axis=1)

cm = confusion_matrix(testing_label_seq, y_pred) 
error1=np.sqrt(metrics.mean_squared_error(y_pred,testing_label_seq))
error2=metrics.mean_squared_error(y_pred,testing_label_seq)
# Transform to df for easier plotting

print('LSTM \nAccuracy: {0:.2f}'.format(accuracy_score(testing_label_seq, y_pred)*100))

print("Root Mean Squared Error rate : ",error1)
print("Mean Squared Error rate : ",error2)

from numpy.core.numeric import tensordot

stop_words=['am','is','are','were','has','have','had', ":",",","!","&","$", "@"," who","where"]
#text="আমার ত্বকে চুলকানি হয়  বমি হয় ক্লান্তি লাগে  ওজন কম হয়েছে এবং  ত্বক হলুদ  হয়েছে"
text="three Pourquoi les programmeurs veulent des bureaux privÃ©s 911: Pourquoi les programmeurs veulent des bureaux privÃ©s: stackoverflow"
words=text.split()
for w in list(words):  # iterating on a copy since removing will mess things up
    if w in stop_words:
        words.remove(w)
#print(words)
t=' '.join(words)
test=[t]
print(test)

model = load_model("Model.h5")
test_sequences = tokenizer.texts_to_sequences(test)
test_padded = pad_sequences(test_sequences, padding=padding_type , maxlen=max_length)
print(test_padded)
predictions = model.predict(test_padded)
print(predictions)
y_pred = np.argmax(predictions, axis=1)

y,=y_pred

if(y == 0):
  print('Article will be recommend to the student of 1 star as the students knowledge capacity is Very low')
elif(y ==1):
  print('Article will be recommend to the student of 2 star as the students knowledge capacity is Low')
elif(y ==2):
  print('Article will be recommend to the student of 3 star as the students knowledge capacity is Moderate')
else:
  print('Article will be recommend to the student of 4 or 5 star as the students knowledge capacity is High')